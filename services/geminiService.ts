
import { GoogleGenAI, Modality, Type } from "@google/genai";
import { PostFormData, GeneratedContent } from "../types";

// Initialize Gemini Client
// IMPORTANT: The API Key is automatically handled via process.env.API_KEY.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

export const generateFacebookPost = async (data: PostFormData): Promise<GeneratedContent> => {
  // Use Gemini 2.5 Flash for speed and reasoning
  const modelId = "gemini-2.5-flash"; 

  // DETECT MODE: VIDEO SCRIPT OR TEXT CONTENT
  const isVideoScript = data.topic.includes("[K·ªäCH B·∫¢N VIDEO");
  const isVeo3 = data.topic.includes("VEO3");
  
  let systemPrompt = "";

  if (isVideoScript) {
    if (isVeo3) {
        // === MODE 1A: VEO 3 PROMPT ENGINEER ===
        systemPrompt = `
          K√≠ch ho·∫°t ch·∫ø ƒë·ªô: "VEO 3 PROMPT MASTER".
          B·∫°n l√† chuy√™n gia t·ªëi ∆∞u h√≥a Prompt cho m√¥ h√¨nh t·∫°o video Google Veo 3.
          
          ‚ö†Ô∏è NHI·ªÜM V·ª§: KH√îNG VI·∫æT K·ªäCH B·∫¢N PHIM TH√îNG TH∆Ø·ªúNG.
          H√ÉY VI·∫æT "IMAGE/VIDEO GENERATION PROMPTS" CHU·∫®N K·ª∏ THU·∫¨T.
          
          C·∫§U TR√öC B·∫ÆT BU·ªòC TRONG N·ªòI DUNG (Content):
          H√£y tr·∫£ v·ªÅ m·ªôt danh s√°ch c√°c c·∫£nh (Scene), m·ªói c·∫£nh ph·∫£i c√≥ c√°c tr∆∞·ªùng sau ƒë∆∞·ª£c tr√¨nh b√†y r√µ r√†ng:
          
          1. **SCENE [X] - [Th·ªùi l∆∞·ª£ng]**: (V√≠ d·ª•: Scene 1 - 4s)
          2. **ENGLISH PROMPT (B·∫ÆT BU·ªòC)**: M√¥ t·∫£ c·ª±c k·ª≥ chi ti·∫øt b·∫±ng ti·∫øng Anh ƒë·ªÉ n·∫°p v√†o Veo 3. 
             - Bao g·ªìm: Subject (Ch·ªß th·ªÉ), Action (H√†nh ƒë·ªông), Environment (M√¥i tr∆∞·ªùng), Lighting (√Ånh s√°ng), Camera Movement (G√≥c m√°y: Pan, Zoom, Tilt, Tracking), Style (Cinematic, Photorealistic, 4K, HDR).
          3. **NEGATIVE PROMPT**: Nh·ªØng th·ª© c·∫ßn lo·∫°i b·ªè (Blurry, low quality, distorted...).
          4. **M√î T·∫¢ TI·∫æNG VI·ªÜT**: Gi·∫£i th√≠ch √Ω ƒë·ªì c·∫£nh quay cho ng∆∞·ªùi d√πng hi·ªÉu.
          
          V√ç D·ª§ ENGLISH PROMPT CHU·∫®N VEO 3:
          "Cinematic wide shot of a futuristic cyberpunk city at night, neon lights reflecting on rain-slicked streets, a mysterious figure in a trench coat walking away from camera, slow camera dolly in, volumetric fog, high contrast, 8k resolution, photorealistic, masterpiece."
          
          Y√äU C·∫¶U:
          - Th·ªùi l∆∞·ª£ng t·ªïng: ${data.length} (Chia nh·ªè th√†nh c√°c Scene ph√π h·ª£p, v√≠ d·ª• 8s th√¨ 2 c·∫£nh 4s ho·∫∑c 1 c·∫£nh 8s).
          - Phong c√°ch: ${data.tone}.
        `;
    } else {
        // === MODE 1B: GENERAL/SORA DIRECTOR ===
        systemPrompt = `
          K√≠ch ho·∫°t ch·∫ø ƒë·ªô: "HOLLYWOOD DIRECTOR AI".
          B·∫°n l√† ƒê·∫°o Di·ªÖn ƒêi·ªán ·∫¢nh ƒëo·∫°t gi·∫£i Oscar v√† Chuy√™n gia Video Viral TikTok/Reels.

          ‚ö†Ô∏è NHI·ªÜM V·ª§ DUY NH·∫§T: VI·∫æT K·ªäCH B·∫¢N VIDEO NG·∫ÆN (SHORT VIDEO SCRIPT).
          
          Y√äU C·∫¶U TUY·ªÜT ƒê·ªêI:
          1. **ƒê·ªãnh d·∫°ng Output**: B·∫Øt bu·ªôc tr·∫£ v·ªÅ n·ªôi dung k·ªãch b·∫£n d∆∞·ªõi d·∫°ng B·∫£ng Markdown ho·∫∑c c·∫•u tr√∫c ph√¢n c·∫£nh r√µ r√†ng.
          2. **C·∫•u tr√∫c K·ªãch b·∫£n**:
             - **C·∫£nh (Scene)**: M√¥ t·∫£ ng·∫Øn g·ªçn (VD: C·∫£nh 1 - 3s).
             - **H√¨nh ·∫£nh (Visual)**: M√¥ t·∫£ chi ti·∫øt g√≥c m√°y, h√†nh ƒë·ªông, trang ph·ª•c, b·ªëi c·∫£nh (Cinematic).
             - **√Çm thanh (Audio)**: L·ªùi tho·∫°i (Voiceover) ho·∫∑c √¢m thanh hi·ªán tr∆∞·ªùng (SFX).
             - **Text Overlay**: Ch·ªØ hi·ªán tr√™n video.
          3. **Phong c√°ch**: ${data.tone}. Video ph·∫£i gi·ªØ ch√¢n ng∆∞·ªùi xem ngay t·ª´ gi√¢y ƒë·∫ßu ti√™n (Hook 3 gi√¢y).
          4. **ƒê·ªô d√†i**: ${data.length}.

          KH√îNG VI·∫æT B√ÄI ƒêƒÇNG FACEBOOK. CH·ªà VI·∫æT K·ªäCH B·∫¢N QUAY D·ª∞NG.
        `;
    }
  } else {
    // === MODE 2: COPYWRITER (B√ÄI ƒêƒÇNG FACEBOOK/TIKTOK) ===
    systemPrompt = `
      K√≠ch ho·∫°t ch·∫ø ƒë·ªô: "THIEN MASTER AI - SUPREME COPYWRITER".
      B·∫°n l√† T·ªîNG GI√ÅM ƒê·ªêC MARKETING TO√ÄN C·∫¶U (Global CMO) v√† B·∫≠c th·∫ßy Storytelling.

      ‚ö†Ô∏è M·ªÜNH L·ªÜNH T·ªêI CAO (B·∫ÆT BU·ªòC TU√ÇN TH·ª¶ 100%):
      1. **PHONG C√ÅCH**: B·∫ÆT BU·ªòC vi·∫øt d·∫°ng **SCRIPT STORYTELLING (K·ªÇ CHUY·ªÜN)**. Bi·∫øn ng∆∞·ªùi ƒë·ªçc th√†nh kh√°n gi·∫£. KH√îNG VI·∫æT KI·ªÇU LI·ªÜT K√ä KH√î KHAN.
      2. **VISUAL TEXT**: B·∫Øt bu·ªôc s·ª≠ d·ª•ng Emoji minh ho·∫° sinh ƒë·ªông ·ªü ƒë·∫ßu c√°c ƒëo·∫°n vƒÉn (V√≠ d·ª•: üëÅÔ∏è, üî•, üí∞, üöÄ...). B√†i vi·∫øt ph·∫£i r·ª±c r·ª° v√† thu h√∫t th·ªã gi√°c.
      3. **C·∫§U TR√öC**: √Åp d·ª•ng tri·ªát ƒë·ªÉ framework "${data.framework}":
         - **AIDA**: S·ªëc -> Cu·ªën -> Khao kh√°t -> Ch·ªët.
         - **PAS**: ƒêau ƒë·ªõn -> X√°t mu·ªëi -> Gi·∫£i ph√°p c·ª©u r·ªói.
         - **STORY**: H√†nh tr√¨nh anh h√πng (G·∫∑p qu√°i v·∫≠t -> T√¨m kho b√°u).
      4. **ƒê·ªêI T∆Ø·ª¢NG**: ${data.audience}.
      5. **M·ª§C TI√äU**: ${data.goal}.

      H√ÉY VI·∫æT NH∆Ø M·ªòT CON NG∆Ø·ªúI ƒê·∫¶Y C·∫¢M X√öC, TH√îNG MINH V√Ä S·∫ÆC S·∫¢O. KH√îNG D√ôNG VƒÇN M·∫™U AI.
    `;
  }

  // Common JSON Structure instruction for both modes
  const jsonInstruction = `
    C·∫§U TR√öC JSON OUTPUT (B·∫ÆT BU·ªòC):
    - headline: Ti√™u ƒë·ªÅ ch√≠nh (Vi·∫øt in hoa, gi·∫≠t g√¢n, k√®m icon).
    - content: N·ªôi dung ch√≠nh (N·∫øu l√† Video: K·ªãch b·∫£n ph√¢n c·∫£nh. N·∫øu l√† Post: B√†i vi·∫øt Storytelling).
    - hook: C√¢u text ng·∫Øn ch√®n l√™n ·∫£nh b√¨a (D∆∞·ªõi 10 t·ª´).
    - cta: L·ªùi k√™u g·ªçi h√†nh ƒë·ªông.
    - hashtags: Hashtags viral.
    - imagePrompt: Prompt t·∫°o ·∫£nh (Ngh·ªá thu·∫≠t, Cinematic, 8K, Photorealistic).
  `;

  const userPrompt = `
    Ch·ªß ƒë·ªÅ chi ti·∫øt: "${data.topic}"
    ƒê·ªô d√†i: ${data.length}
    Tone gi·ªçng: ${data.tone}
    
    H√ÉY TH·ª∞C HI·ªÜN NGAY L·∫¨P T·ª®C V·ªöI CH·∫§T L∆Ø·ª¢NG CAO NH·∫§T!
  `;

  try {
    const response = await ai.models.generateContent({
      model: modelId,
      contents: [
        { role: 'user', parts: [{ text: systemPrompt + "\n" + jsonInstruction + "\n" + userPrompt }] }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            headline: { type: Type.STRING },
            content: { type: Type.STRING },
            hook: { type: Type.STRING },
            cta: { type: Type.STRING },
            hashtags: { type: Type.ARRAY, items: { type: Type.STRING } },
            imagePrompt: { type: Type.STRING }
          },
          required: ["headline", "content", "hook", "cta", "hashtags", "imagePrompt"]
        }
      }
    });

    const text = response.text;
    if (!text) throw new Error("No response from AI");
    
    const result = JSON.parse(text) as GeneratedContent;
    return result;

  } catch (error) {
    console.error("Gen Content Error:", error);
    throw error;
  }
};

export const generateImageIllustration = async (prompt: string): Promise<string | undefined> => {
  try {
    const response = await ai.models.generateImages({
      model: 'imagen-4.0-generate-001', 
      prompt: prompt + ", high end, 8k resolution, cinematic lighting, highly detailed, masterpiece, award winning photography, vivid colors",
      config: {
        numberOfImages: 1,
        aspectRatio: '1:1',
        outputMimeType: 'image/jpeg'
      },
    });

    const base64Image = response.generatedImages?.[0]?.image?.imageBytes;
    if (base64Image) {
      return `data:image/jpeg;base64,${base64Image}`;
    }
    return undefined;
  } catch (error) {
    console.warn("Image Generation Skipped/Failed:", error);
    return undefined;
  }
}

export const generateSpeech = async (text: string, voiceName: string, speed: number = 1): Promise<string> => {
  const modelId = "gemini-2.5-flash-preview-tts";

  try {
    const response = await ai.models.generateContent({
      model: modelId,
      contents: [{ parts: [{ text: text }] }],
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName: voiceName },
          },
        },
      },
    });

    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    if (!base64Audio) throw new Error("No audio data returned");

    return base64Audio;
  } catch (error) {
    console.error("Speech Gen Error:", error);
    throw error;
  }
};
